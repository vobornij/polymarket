{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c54615c",
   "metadata": {},
   "source": [
    "# BTC GARCH & Realized Variance Visualization\n",
    "\n",
    "This notebook loads a JSONL file containing BTC 5-minute price data and GARCH model outputs, then:\n",
    "\n",
    "- Computes rolling realized variance over 1h, 4h, and 1d windows (sum of squared log returns).\n",
    "- Detects available GARCH-related variance/sigma columns automatically.\n",
    "- Plots BTC price on the primary y-axis and realized variances plus GARCH estimates on the secondary y-axis using Plotly.\n",
    "\n",
    "Adjust the `DATA_FILE` path below if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83b714ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cap threshold (95th percentile of squared returns): 8.24250682159075e-06\n",
      "Percentile 0.5 of squared returns: 3.9543184733916117e-07\n",
      "Percentile 0.9 of squared returns: 4.377826134165889e-06\n",
      "Percentile 0.99 of squared returns: 2.6930827569600624e-05\n",
      "Detected additional variance columns (excluding key ones):\n",
      "['sigma']\n",
      "95th percentile squared return cap: 8.24e-06\n",
      "Detected additional variance columns (excluding key ones):\n",
      "['sigma']\n",
      "95th percentile squared return cap: 8.24e-06\n"
     ]
    }
   ],
   "source": [
    "# Load BTC 5‑min data + GARCH outputs and plot price vs realized & GARCH variances\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Path to data file (adjust if necessary)\n",
    "DATA_FILE = Path(\"/Users/vobornij/projects/polybot/build/estimator/btc_5min_with_var.jsonl\")\n",
    "\n",
    "if not DATA_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Data file not found: {DATA_FILE}\")\n",
    "\n",
    "# Load JSONL (expects at least: timestamp, price (or close), plus GARCH output columns)\n",
    "df = pd.read_json(DATA_FILE, lines=True)\n",
    "\n",
    "# Flexible price column detection\n",
    "price_col_candidates = [c for c in ['price','close','btc_price','BTC'] if c in df.columns]\n",
    "if not price_col_candidates:\n",
    "    raise ValueError(\"Could not find a price column among expected candidates: price/close/btc_price/BTC\")\n",
    "PRICE_COL = price_col_candidates[0]\n",
    "\n",
    "# Normalize timestamp column name\n",
    "if 'timestamp' not in df.columns:\n",
    "    # Try common alternatives\n",
    "    ts_alts = [c for c in df.columns if c.lower() in {'time','datetime','date','ts'}]\n",
    "    if not ts_alts:\n",
    "        raise ValueError(\"Expected 'timestamp' column (or time/datetime/date/ts) not found.\")\n",
    "    df.rename(columns={ts_alts[0]: 'timestamp'}, inplace=True)\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Compute log returns on 5-min bars (if not already present)\n",
    "if 'log_return' not in df.columns:\n",
    "    df['prev_price'] = df[PRICE_COL].shift(1)\n",
    "    df['log_return'] = np.log(df[PRICE_COL] / df['prev_price'])\n",
    "\n",
    "# Window sizes in 5‑min bars (assuming constant sampling interval)\n",
    "WIN_1H = 12          # 12 * 5m = 60m\n",
    "WIN_4H = 12 * 4      # 48\n",
    "WIN_1D = 12 * 24     # 288\n",
    "\n",
    "# Realized variance (sum of squared log returns over window, then average per bar by dividing by count)\n",
    "ret2 = df['log_return']**2\n",
    "\n",
    "df['sigma'] = np.sqrt(df['sigma2'])\n",
    "\n",
    "# 95th percentile cap (global) for squared returns to create a robust realized variance variant\n",
    "cap_threshold = ret2.quantile(0.95)\n",
    "# Basic percentile diagnostics\n",
    "if 'ret2_percentile_stats_printed' not in df.attrs:\n",
    "    print(\"Cap threshold (95th percentile of squared returns):\", cap_threshold)\n",
    "    for p in [0.5, 0.90, 0.99]:\n",
    "        print(f\"Percentile {p} of squared returns:\", ret2.quantile(p))\n",
    "    df.attrs['ret2_percentile_stats_printed'] = True\n",
    "\n",
    "ret2_capped = ret2.clip(upper=cap_threshold)\n",
    "\n",
    "# Standard realized variance (average per 5m bar over horizon)\n",
    "df['rv_1h'] = ret2.rolling(WIN_1H, min_periods=WIN_1H).sum()/WIN_1H\n",
    "df['rv_4h'] = ret2.rolling(WIN_4H, min_periods=WIN_4H).sum()/WIN_4H\n",
    "df['rv_1d'] = ret2.rolling(WIN_1D, min_periods=WIN_1D).sum()/WIN_1D\n",
    "\n",
    "# Capped 1h realized variance (average per 5m bar)\n",
    "df['rv_1h_capped'] = ret2_capped.rolling(WIN_1H, min_periods=WIN_1H).sum()/WIN_1H\n",
    "df['rv_4h_capped'] = ret2_capped.rolling(WIN_4H, min_periods=WIN_4H).sum()/WIN_4H\n",
    "\n",
    "# Key variance columns explicitly handled\n",
    "key_variance_cols = [\n",
    "    ('sigma2', 'Model sigma2', '#d62728', 'solid', 1.2),\n",
    "    ('sigma', 'Model sigma', '#d62728', 'solid', 1.2),\n",
    "    ('backbone_sigma2', 'Backbone sigma2', '#9467bd', 'dash', 1),\n",
    "    ('template_sigma2', 'Template sigma2', '#17becf', 'dot', 1.5)\n",
    "]\n",
    "\n",
    "# Automatically detect OTHER GARCH variance/sigma columns\n",
    "keywords = ('garch','sigma','var','vol')\n",
    "garch_cols = []\n",
    "for c in df.columns:\n",
    "    lc = c.lower()\n",
    "    if any(k in lc for k in keywords):\n",
    "        if c not in {'rv_1h','rv_4h','rv_1d','rv_1h_capped','rv_4h_capped', 'sigma2','backbone_sigma2','template_sigma2', 'seasonal_sigma_factor'} and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            garch_cols.append(c)\n",
    "\n",
    "# Build figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Primary axis: BTC price\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['timestamp'], y=df[PRICE_COL],\n",
    "    name='BTC Price', mode='lines',\n",
    "    line=dict(color='black')), secondary_y=False)\n",
    "\n",
    "# Secondary axis: realized variances\n",
    "rv_traces = [\n",
    "    ('RV 1h', 'rv_1h', '#1f77b4'),\n",
    "    ('RV 1h capped', 'rv_1h_capped', '#1f77b4'),  # same base color, will adjust style\n",
    "    ('RV 4h', 'rv_4h', '#ff7f0e'),\n",
    "    ('RV 4h capped', 'rv_4h_capped', '#ff7f0e'),  # same base color, will adjust style\n",
    "    ('RV 1d', 'rv_1d', '#2ca02c'),\n",
    "]\n",
    "for label, col, color in rv_traces:\n",
    "    style = dict(width=1, color=color)\n",
    "    if 'capped' in label.lower():\n",
    "        style['dash'] = 'dot'\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], y=df[col],\n",
    "        name=label, mode='lines',\n",
    "        line=style,\n",
    "        opacity=0.85 if 'capped' not in label.lower() else 0.9), secondary_y=True)\n",
    "\n",
    "# Secondary axis: key variance series (highlighted)\n",
    "for col, nice_name, color, dash, width in key_variance_cols:\n",
    "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['timestamp'], y=df[col], name=nice_name,\n",
    "            mode='lines',\n",
    "            line=dict(color=color, dash=dash, width=width*2),\n",
    "            opacity=0.95), secondary_y=True)\n",
    "\n",
    "# Secondary axis: OTHER GARCH outputs (lighter dotted)\n",
    "palette = ['#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#1f77b4', '#ff9896']\n",
    "for i, col in enumerate(sorted(garch_cols)):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], y=df[col],\n",
    "        name=col, mode='lines',\n",
    "        line=dict(width=1, dash='dash', color=palette[i % len(palette)]),\n",
    "        opacity=0.6), secondary_y=True)\n",
    "\n",
    "fig.update_yaxes(title_text=\"BTC Price (USD)\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Variance / GARCH Outputs (per 5m avg)\", secondary_y=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"BTC Price vs Realized Variance (1h / 4h / 1d, capped 1h) and Model Variance Components\",\n",
    "    hovermode='x unified',\n",
    "    legend=dict(orientation='h', y=1.02, x=0),\n",
    "    height=750,\n",
    "    margin=dict(l=60, r=40, t=60, b=40)\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Display a quick list of detected variance-related columns\n",
    "print(\"Detected additional variance columns (excluding key ones):\")\n",
    "print(garch_cols)\n",
    "print(f\"95th percentile squared return cap: {cap_threshold:.2e}\")\n",
    "\n",
    "# Ratios for quick diagnostics if template/backbone/model present\n",
    "if all(col in df.columns for col in ['sigma2','backbone_sigma2','template_sigma2']):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio_model_template = (df['sigma2'] / df['template_sigma2']).replace([np.inf,-np.inf], np.nan)\n",
    "        ratio_backbone_template = (df['backbone_sigma2'] / df['template_sigma2']).replace([np.inf,-np.inf], np.nan)\n",
    "        print('Median sigma2 / template_sigma2:', ratio_model_template.median())\n",
    "        print('Median backbone_sigma2 / template_sigma2:', ratio_backbone_template.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e09fac0",
   "metadata": {},
   "source": [
    "## Compare model variance outputs to forward 1h realized variance\n",
    "\n",
    "We now have additional fields in the data:\n",
    "\n",
    "- `seasonal_sigma_factor`: seasonal multiplicative factor applied to volatility (sigma), not variance.\n",
    "- `sigma2`: model conditional variance (after applying seasonality) per 5-minute bar.\n",
    "- `backbone_sigma2`: underlying (deseasoned) variance component (should explain variance of `deseasoned_log_return`).\n",
    "- `deseasoned_log_return`: return with intraday seasonal sigma removed (i.e., original log return divided by seasonal sigma factor if constructed that way).\n",
    "\n",
    "Goals:\n",
    "1. Compute forward 1h realized variance of raw log returns (`fwd_rv_1h`) and compare with `sigma2` (optionally aggregated to 1h).\n",
    "2. Compute forward 1h realized variance of deseasoned log returns (`fwd_rv_deseasoned_1h`) and compare with `backbone_sigma2`.\n",
    "3. Visualize all series.\n",
    "\n",
    "Forward 1h realized variance at time t uses returns from (t, t+1h]; constructed via a shifted rolling sum of squared returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc61e9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation (raw): forward RV vs model var = 0.669\n",
      "Correlation (deseasoned): forward RV vs backbone var = 0.633\n",
      "MAE raw RV vs model var: 1.39e-05\n"
     ]
    }
   ],
   "source": [
    "# Compute forward 1h realized variance (raw and deseasoned) and compare with model variance outputs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Ensure needed columns exist\n",
    "required_cols = {'log_return','sigma2','backbone_sigma2'}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# If deseasoned_log_return not present, attempt to reconstruct using seasonal_sigma_factor\n",
    "if 'deseasoned_log_return' not in df.columns:\n",
    "    if 'seasonal_sigma_factor' in df.columns:\n",
    "        # Assuming original: log_return = deseasoned_log_return * seasonal_sigma_factor\n",
    "        # Then deseasoned = log_return / seasonal_sigma_factor\n",
    "        df['deseasoned_log_return'] = df['log_return'] / df['seasonal_sigma_factor']\n",
    "    else:\n",
    "        df['deseasoned_log_return'] = np.nan\n",
    "\n",
    "BAR_PER_HOUR = 12\n",
    "\n",
    "# Forward realized variance: sum_{t+1 to t+12} r^2. We can use rolling sum on shifted series.\n",
    "# Shift - (negative) moves future returns backward so they align with current timestamp.\n",
    "ret2 = df['log_return']**2\n",
    "fwd_rv_raw = ret2.shift(-1).rolling(BAR_PER_HOUR, min_periods=BAR_PER_HOUR).sum()\n",
    "# Deseasoned\n",
    "ret2_des = df['deseasoned_log_return']**2\n",
    "fwd_rv_des = ret2_des.shift(-1).rolling(BAR_PER_HOUR, min_periods=BAR_PER_HOUR).sum()\n",
    "\n",
    "# Store\n",
    "df['fwd_rv_1h'] = fwd_rv_raw\n",
    "df['fwd_rv_deseasoned_1h'] = fwd_rv_des\n",
    "\n",
    "# Optionally scale model variance to 1h horizon for comparison (sum of next 12 conditional variances)\n",
    "# We'll compute forward 1h model variance by summing sigma2 forward (and backbone separately)\n",
    "model_var_fwd = df['sigma2'].shift(-1).rolling(BAR_PER_HOUR, min_periods=BAR_PER_HOUR).sum()\n",
    "backbone_var_fwd = df['backbone_sigma2'].shift(-1).rolling(BAR_PER_HOUR, min_periods=BAR_PER_HOUR).sum()\n",
    "\n",
    "df['fwd_model_var_1h'] = model_var_fwd\n",
    "df['fwd_backbone_var_1h'] = backbone_var_fwd\n",
    "\n",
    "# Template variance forward 1h if available\n",
    "if 'template_sigma2' in df.columns and pd.api.types.is_numeric_dtype(df['template_sigma2']):\n",
    "    df['fwd_template_var_1h'] = df['template_sigma2'].shift(-1).rolling(BAR_PER_HOUR, min_periods=BAR_PER_HOUR).sum()\n",
    "else:\n",
    "    df['fwd_template_var_1h'] = np.nan\n",
    "\n",
    "# Build comparison figure\n",
    "fig2 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Primary y: BTC price\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=df['timestamp'], y=df[PRICE_COL], name='BTC Price',\n",
    "    line=dict(color='black'), opacity=0.7), secondary_y=False)\n",
    "\n",
    "# Secondary y: variance series (raw)\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=df['timestamp'], y=df['fwd_rv_1h'], name='Forward 1h RV (raw)',\n",
    "    line=dict(color='#1f77b4')), secondary_y=True)\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=df['timestamp'], y=df['fwd_model_var_1h'], name='Forward 1h Model Var (sigma2 sum)',\n",
    "    line=dict(color='#ff7f0e')), secondary_y=True)\n",
    "\n",
    "# Template variance (if present)\n",
    "if df['fwd_template_var_1h'].notna().any():\n",
    "    fig2.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], y=df['fwd_template_var_1h'], name='Forward 1h Template Var (sum)',\n",
    "        line=dict(color='#17becf', dash='dot')), secondary_y=True)\n",
    "\n",
    "# Secondary y: deseasoned comparison (dotted)\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=df['timestamp'], y=df['fwd_rv_deseasoned_1h'], name='Forward 1h RV (deseasoned)',\n",
    "    line=dict(color='#2ca02c', dash='dot')), secondary_y=True)\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=df['timestamp'], y=df['fwd_backbone_var_1h'], name='Forward 1h Backbone Var (sum)',\n",
    "    line=dict(color='#d62728', dash='dash')), secondary_y=True)\n",
    "\n",
    "fig2.update_yaxes(title_text='BTC Price (USD)', secondary_y=False)\n",
    "fig2.update_yaxes(title_text='Variance (1h forward)', secondary_y=True)\n",
    "fig2.update_layout(title='Forward 1h Realized Variance vs Model / Template / Backbone Variance Components',\n",
    "                   hovermode='x unified', legend=dict(orientation='h', y=1.03, x=0), height=700)\n",
    "fig2.show(renderer='browser')\n",
    "\n",
    "# Basic evaluation metrics: correlations\n",
    "valid_mask_raw = df['fwd_rv_1h'].notna() & df['fwd_model_var_1h'].notna()\n",
    "valid_mask_template = df['fwd_rv_1h'].notna() & df['fwd_template_var_1h'].notna()\n",
    "valid_mask_des = df['fwd_rv_deseasoned_1h'].notna() & df['fwd_backbone_var_1h'].notna()\n",
    "\n",
    "if valid_mask_raw.sum() > 10:\n",
    "    corr_raw = np.corrcoef(df.loc[valid_mask_raw, 'fwd_rv_1h'], df.loc[valid_mask_raw, 'fwd_model_var_1h'])[0,1]\n",
    "    print(f\"Correlation (raw): forward RV vs model var = {corr_raw:.3f}\")\n",
    "if valid_mask_template.sum() > 10:\n",
    "    corr_template = np.corrcoef(df.loc[valid_mask_template, 'fwd_rv_1h'], df.loc[valid_mask_template, 'fwd_template_var_1h'])[0,1]\n",
    "    print(f\"Correlation (raw): forward RV vs template var = {corr_template:.3f}\")\n",
    "if valid_mask_des.sum() > 10:\n",
    "    corr_des = np.corrcoef(df.loc[valid_mask_des, 'fwd_rv_deseasoned_1h'], df.loc[valid_mask_des, 'fwd_backbone_var_1h'])[0,1]\n",
    "    print(f\"Correlation (deseasoned): forward RV vs backbone var = {corr_des:.3f}\")\n",
    "\n",
    "# Relative error metrics (MAE) for raw realized variance comparisons\n",
    "if valid_mask_raw.sum() > 10:\n",
    "    mae_model = np.mean(np.abs(df.loc[valid_mask_raw, 'fwd_rv_1h'] - df.loc[valid_mask_raw, 'fwd_model_var_1h']))\n",
    "    print(f\"MAE raw RV vs model var: {mae_model:.2e}\")\n",
    "if valid_mask_template.sum() > 10:\n",
    "    mae_template = np.mean(np.abs(df.loc[valid_mask_template, 'fwd_rv_1h'] - df.loc[valid_mask_template, 'fwd_template_var_1h']))\n",
    "    print(f\"MAE raw RV vs template var: {mae_template:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "216353c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averageMu5min=0.0\n"
     ]
    }
   ],
   "source": [
    "# Weekly seasonal sigma template: EXPECTS new structure (sigmaEwmShrunkNormalized, sigmaEwmFactor) without defensive checks\n",
    "import json, pandas as pd, numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "TEMPLATE_FILE = Path(\"/Users/vobornij/projects/polybot/build/estimator/btc_sigma_template_5min.json\")\n",
    "with open(TEMPLATE_FILE, \"r\") as f:\n",
    "    tpl = json.load(f)\n",
    "\n",
    "avg_mu_5m = tpl[\"averageMu5min\"]\n",
    "\n",
    "rows = []\n",
    "for e in tpl[\"template\"]:  # assume list exists\n",
    "    k = e[\"key\"]\n",
    "    day = k[\"day\"]\n",
    "    hour = k[\"hour\"]\n",
    "    idx5 = k[\"interval5minIndex\"]\n",
    "    weekly_interval = day*24*12 + hour*12 + idx5\n",
    "    sigma = e[\"sigma\"]\n",
    "    sigma_norm = e[\"sigmaEwmShrunkNormalized\"]\n",
    "    sigma_factor = e[\"sigmaEwmFactor\"]\n",
    "    seasonal_sigma = sigma_norm * sigma_factor\n",
    "    rows.append({\n",
    "        \"day\": day,\n",
    "        \"hour\": hour,\n",
    "        \"interval5\": idx5,\n",
    "        \"weekly_interval\": weekly_interval,\n",
    "        \"sigma\": sigma,\n",
    "        \"sigmaEwmShrunkNormalized\": sigma_norm,\n",
    "        \"sigmaEwmFactor\": sigma_factor,\n",
    "        \"seasonalSigma\": seasonal_sigma,\n",
    "    })\n",
    "\n",
    "df_tpl = pd.DataFrame(rows).sort_values(\"weekly_interval\").reset_index(drop=True)\n",
    "expected = 7*24*12\n",
    "if len(df_tpl) != expected:\n",
    "    raise ValueError(f\"Template length {len(df_tpl)} != expected {expected}\")\n",
    "\n",
    "# Time alignment (last completed UTC week start)\n",
    "now = datetime.now(timezone.utc)\n",
    "start_current_week = (now - timedelta(days=now.weekday())).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "week_start = start_current_week - timedelta(days=7)\n",
    "df_tpl[\"week_time_utc\"] = week_start + pd.to_timedelta(df_tpl[\"weekly_interval\"]*5, unit=\"m\")\n",
    "\n",
    "# Require all needed columns\n",
    "required_cols = [\"sigma\",\"sigmaEwmShrunkNormalized\",\"sigmaEwmFactor\",\"seasonalSigma\"]\n",
    "missing = [c for c in required_cols if c not in df_tpl.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns in template: {missing}\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_tpl['week_time_utc'], y=df_tpl['sigma'], name='Sigma (raw)', mode='lines', line=dict(color='#17becf', width=1.2)))\n",
    "fig.add_trace(go.Scatter(x=df_tpl['week_time_utc'], y=df_tpl['seasonalSigma'], name='Seasonal σ (norm * factor)', mode='lines', line=dict(color='#ff7f0e', width=1.4)))\n",
    "fig.add_trace(go.Scatter(x=df_tpl['week_time_utc'], y=df_tpl['sigmaEwmShrunkNormalized'], name='σ Norm (shape)', mode='lines', line=dict(color='#2ca02c', dash='dot', width=1)))\n",
    "fig.add_trace(go.Scatter(x=df_tpl['week_time_utc'], y=df_tpl['sigmaEwmFactor'], name='σ Factor', mode='lines', line=dict(color='#9467bd', dash='dash', width=1)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Weekly Seasonal Sigma Pattern (last completed UTC week start {week_start.date()})\",\n",
    "    xaxis_title=\"UTC Time (last completed week)\",\n",
    "    yaxis_title=\"Sigma / Components\",\n",
    "    hovermode='x unified',\n",
    "    legend=dict(orientation='h', y=1.02, x=0),\n",
    "    height=420,\n",
    "    margin=dict(l=55, r=30, t=55, b=40)\n",
    ")\n",
    "for d in range(1,7):\n",
    "    fig.add_vline(x=week_start + timedelta(days=d), line_width=1, line_dash='dot', line_color='rgba(90,90,90,0.35)')\n",
    "fig.show(renderer='browser')\n",
    "\n",
    "print(f\"averageMu5min={avg_mu_5m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "206d78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, pandas as pd, plotly.graph_objects as go, numpy as np\n",
    "\n",
    "# Realized variance file (5m)\n",
    "rv_path = Path('/Users/vobornij/projects/polymarket/data/btc/rv/5m/btc_rv5m_20250519_000000_to_20250526_000000.jsonl')\n",
    "rows = [json.loads(l) for l in rv_path.read_text().splitlines() if l.strip()]\n",
    "rv_df = pd.DataFrame(rows)\n",
    "rv_df['intervalStart'] = pd.to_datetime(rv_df['intervalStart'])\n",
    "rv_df['intervalEnd'] = pd.to_datetime(rv_df['intervalEnd'])\n",
    "rv_df['mid_ts'] = rv_df['intervalStart'] + (rv_df['intervalEnd'] - rv_df['intervalStart'])/2\n",
    "rv_df = rv_df.sort_values('mid_ts').reset_index(drop=True)\n",
    "\n",
    "# 1h rolling realized variance (sum of 12 consecutive 5m RV values), normalize per-5m, then convert to sigma\n",
    "rv_df['rv_1h_sum'] = rv_df['realizedVariance'].rolling(12, min_periods=12).sum()\n",
    "rv_df['rv_1h_per5m'] = rv_df['rv_1h_sum'] / 12.0\n",
    "\n",
    "# Convert variances to standard deviations (per 5m)\n",
    "rv_df['sigma_5m'] = np.sqrt(rv_df['realizedVariance'])\n",
    "rv_df['sigma_1h_per5m'] = np.sqrt(rv_df['rv_1h_per5m'])\n",
    "\n",
    "# Crop model variance to same time span and convert to sigma\n",
    "mask = (df['timestamp'] >= rv_df['intervalStart'].min()) & (df['timestamp'] <= rv_df['intervalEnd'].max())\n",
    "df_sigma = df.loc[mask, ['timestamp','sigma2']].dropna().copy()\n",
    "df_sigma['sigma'] = np.sqrt(df_sigma['sigma2'])\n",
    "\n",
    "\n",
    "rv_df['weekly_interval'] = (rv_df['mid_ts'].dt.dayofweek * 24 * 12\n",
    "                            + rv_df['mid_ts'].dt.hour * 12\n",
    "                            + (rv_df['mid_ts'].dt.minute // 5))\n",
    "pattern = df_tpl.set_index('weekly_interval')['seasonalSigma']\n",
    "seasonal_sigma = pattern.reindex(rv_df['weekly_interval']).values\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=rv_df['mid_ts'], y=rv_df['sigma_5m'], name='Sigma 5m (realized)', mode='lines', line=dict(color='#1f77b4', width=1)))\n",
    "fig.add_trace(go.Scatter(x=rv_df['mid_ts'], y=rv_df['sigma_1h_per5m'], name='Sigma 1h (per 5m avg)', mode='lines', line=dict(color='#2ca02c', dash='dash', width=2), opacity=0.9))\n",
    "fig.add_trace(go.Scatter(x=df_sigma['timestamp'], y=df_sigma['sigma'], name='Sigma (model)', mode='lines', line=dict(color='#d62728', width=1)))\n",
    "fig.add_trace(go.Scatter(x=rv_df['mid_ts'], y=seasonal_sigma, name='Seasonal Sigma (template)', mode='lines', line=dict(color='#9467bd', dash='dot', width=2), opacity=0.85))\n",
    "\n",
    "fig.update_layout(title='BTC 5m Realized Sigma vs Model Sigma + Seasonal Pattern',\n",
    "                  yaxis_title='Sigma (per 5m)', xaxis_title='Time', hovermode='x unified',\n",
    "                  legend=dict(orientation='h', y=1.02, x=0))\n",
    "fig.show(renderer='browser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polymarket-analysis-BY1ldWyW-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
