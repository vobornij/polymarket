{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29ca11f",
   "metadata": {},
   "source": [
    "# Polymarket Crypto Arbitrage Analysis\n",
    "\n",
    "This notebook demonstrates how to use the Polymarket analysis framework to:\n",
    "1. Collect market data from Polymarket\n",
    "2. Process and clean the data\n",
    "3. Detect arbitrage opportunities\n",
    "4. Backtest trading strategies\n",
    "5. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our analysis modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from polymarket_analysis.data.data_collector import DataCollector\n",
    "from polymarket_analysis.data.data_processor import DataProcessor\n",
    "from polymarket_analysis.strategies.arbitrage_detector import ArbitrageDetector\n",
    "from polymarket_analysis.strategies.strategy_backtester import StrategyBacktester\n",
    "from polymarket_analysis.visualization.dashboard import PolymarketVisualizer\n",
    "from polymarket_analysis.utils.config import config\n",
    "from polymarket_analysis.utils.logger import get_default_logger\n",
    "\n",
    "# Set up logging\n",
    "logger = get_default_logger()\n",
    "print(\"Polymarket Analysis Framework Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23434ff",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "First, let's collect crypto market data from Polymarket and reference prices from Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data collector\n",
    "collector = DataCollector()\n",
    "\n",
    "# Collect complete dataset\n",
    "# Note: This will make API calls to Polymarket and Yahoo Finance\n",
    "print(\"Starting data collection...\")\n",
    "print(\"This may take a few minutes depending on API rate limits...\")\n",
    "\n",
    "try:\n",
    "    markets, histories, crypto_prices = await collector.collect_complete_dataset(\n",
    "        days_back=7,  # Start with 7 days for demo\n",
    "        min_volume=500,  # Lower threshold for demo\n",
    "        crypto_symbols=['BTC-USD', 'ETH-USD', 'SOL-USD']\n",
    "    )\n",
    "    \n",
    "    print(f\"Collected {len(markets)} markets\")\n",
    "    print(f\"Collected price histories for {len(histories)} markets\")\n",
    "    print(f\"Collected reference prices for {crypto_prices.shape[1]} crypto symbols\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during data collection: {e}\")\n",
    "    print(\"Using mock data for demonstration...\")\n",
    "    \n",
    "    # Create mock data for demonstration\n",
    "    import random\n",
    "    from polymarket_analysis.api.polymarket_client import Market, PricePoint\n",
    "    \n",
    "    # Mock markets\n",
    "    markets = [\n",
    "        Market(\n",
    "            id=f\"market_{i}\",\n",
    "            question=f\"Will Bitcoin reach ${40000 + i*1000} by end of 2025?\",\n",
    "            description=\"Bitcoin price prediction market\",\n",
    "            end_date=datetime.now() + timedelta(days=30),\n",
    "            outcome_prices={\"Yes\": 0.6 + random.uniform(-0.2, 0.2), \"No\": 0.4 + random.uniform(-0.2, 0.2)},\n",
    "            volume=random.uniform(1000, 10000),\n",
    "            liquidity=random.uniform(500, 5000),\n",
    "            active=True,\n",
    "            tags=[\"crypto\", \"bitcoin\"]\n",
    "        )\n",
    "        for i in range(5)\n",
    "    ]\n",
    "    \n",
    "    # Mock price histories\n",
    "    histories = {}\n",
    "    base_time = datetime.now() - timedelta(days=7)\n",
    "    \n",
    "    for market in markets:\n",
    "        price_points = []\n",
    "        current_price = 0.5\n",
    "        \n",
    "        for hour in range(168):  # 7 days * 24 hours\n",
    "            timestamp = base_time + timedelta(hours=hour)\n",
    "            current_price += random.uniform(-0.05, 0.05)\n",
    "            current_price = max(0.01, min(0.99, current_price))\n",
    "            \n",
    "            price_points.append(PricePoint(\n",
    "                market_id=market.id,\n",
    "                outcome=\"Yes\",\n",
    "                price=current_price,\n",
    "                timestamp=timestamp,\n",
    "                volume=random.uniform(10, 100)\n",
    "            ))\n",
    "        \n",
    "        histories[market.id] = price_points\n",
    "    \n",
    "    # Mock crypto prices\n",
    "    timestamps = pd.date_range(base_time, periods=168, freq='H')\n",
    "    crypto_prices = pd.DataFrame({\n",
    "        'BTC-USD': np.cumsum(np.random.randn(168) * 100) + 50000,\n",
    "        'ETH-USD': np.cumsum(np.random.randn(168) * 50) + 3000,\n",
    "        'SOL-USD': np.cumsum(np.random.randn(168) * 5) + 100\n",
    "    }, index=timestamps)\n",
    "    \n",
    "    print(\"Mock data created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3b4b5",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "\n",
    "Now let's process the collected data and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e71c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Convert data to DataFrames\n",
    "markets_df = processor.create_market_dataframe(markets)\n",
    "price_df = processor.create_price_dataframe(histories, outcome_filter=\"Yes\")\n",
    "\n",
    "print(\"Market Data:\")\n",
    "print(markets_df.head())\n",
    "print(f\"\\nPrice Data Shape: {price_df.shape}\")\n",
    "print(price_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate technical features\n",
    "price_features_df = processor.calculate_price_features(price_df)\n",
    "\n",
    "# Align with crypto prices\n",
    "aligned_df = processor.align_crypto_prices(price_features_df, crypto_prices)\n",
    "\n",
    "print(f\"Features added. New shape: {price_features_df.shape}\")\n",
    "print(f\"Aligned data shape: {aligned_df.shape}\")\n",
    "print(\"\\nNew columns:\")\n",
    "print([col for col in price_features_df.columns if col not in price_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e15ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect potential arbitrage opportunities\n",
    "arbitrage_df = processor.detect_arbitrage_opportunities(markets_df)\n",
    "\n",
    "print(f\"Found {len(arbitrage_df)} potential arbitrage opportunities:\")\n",
    "if not arbitrage_df.empty:\n",
    "    print(arbitrage_df[['market1_question', 'market2_question', 'price_diff', 'opportunity_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc54a18",
   "metadata": {},
   "source": [
    "## 3. Arbitrage Signal Detection\n",
    "\n",
    "Let's use our arbitrage detector to find trading opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a435ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arbitrage detector\n",
    "detector = ArbitrageDetector(\n",
    "    lookback_window=24,\n",
    "    confidence_threshold=0.7,\n",
    "    min_return_threshold=0.02\n",
    ")\n",
    "\n",
    "print(\"Arbitrage Detector initialized with:\")\n",
    "print(f\"- Lookback window: {detector.lookback_window} hours\")\n",
    "print(f\"- Confidence threshold: {detector.confidence_threshold}\")\n",
    "print(f\"- Min return threshold: {detector.min_return_threshold:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e713f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect different types of arbitrage opportunities\n",
    "print(\"Detecting arbitrage signals...\")\n",
    "\n",
    "# Mean reversion signals\n",
    "mean_reversion_signals = detector.detect_mean_reversion_opportunities(price_features_df)\n",
    "print(f\"Mean reversion signals: {len(mean_reversion_signals)}\")\n",
    "\n",
    "# Momentum signals\n",
    "momentum_signals = detector.detect_momentum_opportunities(price_features_df)\n",
    "print(f\"Momentum signals: {len(momentum_signals)}\")\n",
    "\n",
    "# Price divergence signals (if crypto data is aligned)\n",
    "if not aligned_df.empty:\n",
    "    divergence_signals = detector.detect_price_divergence_opportunities(\n",
    "        aligned_df, crypto_prices\n",
    "    )\n",
    "    print(f\"Price divergence signals: {len(divergence_signals)}\")\n",
    "else:\n",
    "    divergence_signals = []\n",
    "    print(\"Price divergence signals: 0 (no aligned data)\")\n",
    "\n",
    "# Combine all signals\n",
    "all_signals = mean_reversion_signals + momentum_signals + divergence_signals\n",
    "print(f\"\\nTotal signals detected: {len(all_signals)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd48eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze signal quality\n",
    "if all_signals:\n",
    "    signal_df = pd.DataFrame([\n",
    "        {\n",
    "            'market_id': s.market_id,\n",
    "            'signal_type': s.signal_type,\n",
    "            'timestamp': s.timestamp,\n",
    "            'confidence': s.confidence,\n",
    "            'potential_return': s.potential_return,\n",
    "            'risk_score': s.risk_score\n",
    "        }\n",
    "        for s in all_signals\n",
    "    ])\n",
    "    \n",
    "    print(\"Signal Summary:\")\n",
    "    print(signal_df.groupby('signal_type').agg({\n",
    "        'confidence': ['count', 'mean'],\n",
    "        'potential_return': 'mean',\n",
    "        'risk_score': 'mean'\n",
    "    }).round(3))\n",
    "else:\n",
    "    print(\"No signals to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7000b",
   "metadata": {},
   "source": [
    "## 4. Strategy Backtesting\n",
    "\n",
    "Let's backtest our arbitrage strategies to evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize backtester\n",
    "backtester = StrategyBacktester(\n",
    "    initial_capital=10000,\n",
    "    position_sizing='proportional',\n",
    "    max_position_size=0.1,  # 10% max per trade\n",
    "    transaction_cost=0.01,  # 1%\n",
    "    max_holding_period=12,  # 12 hours max\n",
    "    stop_loss=0.05,  # 5%\n",
    "    take_profit=0.10  # 10%\n",
    ")\n",
    "\n",
    "print(\"Strategy Backtester initialized with:\")\n",
    "print(f\"- Initial capital: ${backtester.initial_capital:,.0f}\")\n",
    "print(f\"- Max position size: {backtester.max_position_size:.1%}\")\n",
    "print(f\"- Transaction cost: {backtester.transaction_cost:.1%}\")\n",
    "print(f\"- Max holding period: {backtester.max_holding_period} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa669f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest\n",
    "if all_signals:\n",
    "    print(\"Running strategy backtest...\")\n",
    "    \n",
    "    performance = backtester.backtest_strategy(\n",
    "        signals=all_signals,\n",
    "        price_data=price_features_df\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== BACKTEST RESULTS ===\")\n",
    "    print(f\"Total Trades: {performance.total_trades}\")\n",
    "    print(f\"Win Rate: {performance.win_rate:.1%}\")\n",
    "    print(f\"Total Return: {performance.total_return:.1%}\")\n",
    "    print(f\"Total P&L: ${performance.total_pnl:.2f}\")\n",
    "    print(f\"Sharpe Ratio: {performance.sharpe_ratio:.2f}\")\n",
    "    print(f\"Max Drawdown: {performance.max_drawdown:.1%}\")\n",
    "    print(f\"Average Trade Duration: {performance.avg_trade_duration:.1f} hours\")\n",
    "    \n",
    "    if performance.winning_trades > 0 and performance.losing_trades > 0:\n",
    "        print(f\"Average Win: ${performance.avg_win:.2f}\")\n",
    "        print(f\"Average Loss: ${performance.avg_loss:.2f}\")\n",
    "        print(f\"Profit Factor: {performance.profit_factor:.2f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No signals available for backtesting\")\n",
    "    performance = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca9f36",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "Let's create comprehensive visualizations of our analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9bc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = PolymarketVisualizer(style='plotly_dark')\n",
    "\n",
    "print(\"Creating visualizations...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62fee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market overview\n",
    "market_overview_fig = visualizer.plot_market_overview(markets_df)\n",
    "market_overview_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price history\n",
    "price_history_fig = visualizer.plot_price_history(price_df)\n",
    "price_history_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188163f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrage signals\n",
    "if all_signals:\n",
    "    signals_fig = visualizer.plot_arbitrage_signals(all_signals, price_df)\n",
    "    signals_fig.show()\n",
    "else:\n",
    "    print(\"No signals to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy performance\n",
    "if performance and performance.total_trades > 0:\n",
    "    performance_fig = visualizer.plot_strategy_performance(performance)\n",
    "    performance_fig.show()\n",
    "else:\n",
    "    print(\"No performance data to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41386e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "if not aligned_df.empty:\n",
    "    correlation_fig = visualizer.plot_correlation_analysis(aligned_df)\n",
    "    correlation_fig.show()\n",
    "else:\n",
    "    print(\"No aligned data for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ada002",
   "metadata": {},
   "source": [
    "## 6. Advanced Analysis\n",
    "\n",
    "Let's perform some advanced analysis including parameter optimization and walk-forward testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter optimization (if we have enough signals)\n",
    "if all_signals and len(all_signals) > 10:\n",
    "    print(\"Running parameter optimization...\")\n",
    "    \n",
    "    # Define parameter ranges to test\n",
    "    parameter_ranges = {\n",
    "        'max_position_size': [0.05, 0.10, 0.15],\n",
    "        'stop_loss': [0.03, 0.05, 0.07],\n",
    "        'take_profit': [0.08, 0.10, 0.12],\n",
    "        'max_holding_period': [8, 12, 16]\n",
    "    }\n",
    "    \n",
    "    optimization_result = backtester.optimize_parameters(\n",
    "        signals=all_signals,\n",
    "        price_data=price_features_df,\n",
    "        parameter_ranges=parameter_ranges\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== OPTIMIZATION RESULTS ===\")\n",
    "    print(f\"Best Parameters: {optimization_result['best_parameters']}\")\n",
    "    print(f\"Best Sharpe Ratio: {optimization_result['optimization_value']:.3f}\")\n",
    "    \n",
    "    best_performance = optimization_result['best_performance']\n",
    "    if best_performance:\n",
    "        print(f\"Optimized Return: {best_performance.total_return:.1%}\")\n",
    "        print(f\"Optimized Win Rate: {best_performance.win_rate:.1%}\")\n",
    "\n",
    "else:\n",
    "    print(\"Not enough signals for parameter optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d7415",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "Let's summarize our analysis and suggest next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a69d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== POLYMARKET ARBITRAGE ANALYSIS SUMMARY ===\")\n",
    "print(f\"Data Collection: {len(markets)} markets, {len(histories)} price histories\")\n",
    "print(f\"Signal Detection: {len(all_signals)} total signals\")\n",
    "\n",
    "if all_signals:\n",
    "    signal_types = pd.Series([s.signal_type for s in all_signals]).value_counts()\n",
    "    print(\"Signal breakdown:\")\n",
    "    for signal_type, count in signal_types.items():\n",
    "        print(f\"  - {signal_type}: {count}\")\n",
    "\n",
    "if performance:\n",
    "    print(f\"\\nBacktest Performance:\")\n",
    "    print(f\"  - Total Return: {performance.total_return:.1%}\")\n",
    "    print(f\"  - Win Rate: {performance.win_rate:.1%}\")\n",
    "    print(f\"  - Sharpe Ratio: {performance.sharpe_ratio:.2f}\")\n",
    "\n",
    "print(\"\\n=== NEXT STEPS ===\")\n",
    "print(\"1. Collect more historical data for robust analysis\")\n",
    "print(\"2. Implement more sophisticated signal detection algorithms\")\n",
    "print(\"3. Add real-time data streaming capabilities\")\n",
    "print(\"4. Integrate with actual trading APIs for live execution\")\n",
    "print(\"5. Implement risk management and position sizing optimization\")\n",
    "print(\"6. Add market microstructure analysis for better execution\")\n",
    "print(\"7. Create automated monitoring and alerting systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1273a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for future analysis\n",
    "print(\"Saving analysis results...\")\n",
    "\n",
    "try:\n",
    "    # Save processed data\n",
    "    processor.save_processed_data(\n",
    "        market_df=markets_df,\n",
    "        price_df=price_features_df,\n",
    "        aligned_df=aligned_df if not aligned_df.empty else None,\n",
    "        arbitrage_df=arbitrage_df if not arbitrage_df.empty else None\n",
    "    )\n",
    "    \n",
    "    # Create comprehensive dashboard\n",
    "    dashboard_figures = visualizer.create_dashboard(\n",
    "        markets_df=markets_df,\n",
    "        price_df=price_df,\n",
    "        signals=all_signals,\n",
    "        performance=performance\n",
    "    )\n",
    "    \n",
    "    print(\"Analysis results saved successfully!\")\n",
    "    print(f\"Check the 'data/processed' directory for CSV files\")\n",
    "    print(f\"Check the 'data/processed/visualizations' directory for HTML plots\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving results: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
